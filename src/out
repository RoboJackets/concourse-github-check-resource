#!/usr/bin/env python3

"""
Calls the GitHub API to create or update a check run
"""
import logging
import sys
from datetime import datetime
from json import dumps, load, loads
from os import getenv, listdir, path, stat
from re import fullmatch
from subprocess import run
from sys import argv, stderr, stdin
from traceback import format_exc
from typing import Dict, List, Union

from requests import patch, post


def timestamp_for_github() -> str:
    """
    Returns a timestamp in the format GitHub expects

    :return: String representation of the current time in ISO 8601 format, in UTC
    """
    return datetime.now().astimezone().replace(microsecond=0).isoformat()


def parse_yamllint_annotations(source_path: str) -> Dict[str, Union[str, List[Dict[str, object]]]]:
    """
    Parses annotations for yammllint

    :param source_path: the path to read for annotations
    :return: output object for the GitHub API
    """
    regex = (
        r"\A\.?\/?(?P<path>.*)\:(?P<line>\d+)\:\d+\: \[(?P<level>warning|error)\] (?P<message>.*) \((?P<rule>.*)\)\Z"
    )
    files = set()
    annotations = []

    yammlint_level_to_github_level = {"warning": "warning", "error": "failure"}

    for source_file in listdir(source_path):
        with open(path.join(source_path, source_file), "r") as file:
            for line in file:
                annotation_parts = fullmatch(regex, line.strip())
                assert annotation_parts, f"Failed to parse line `{line.strip()}`"
                files.add(annotation_parts.group("path"))
                annotations.append(
                    {
                        "path": annotation_parts.group("path"),
                        "start_line": int(annotation_parts.group("line")),
                        "end_line": int(annotation_parts.group("line")),
                        "annotation_level": yammlint_level_to_github_level[annotation_parts.group("level")],
                        "message": annotation_parts.group("message"),
                        "raw_details": dumps(annotation_parts.groupdict()),
                    }
                )

    if len(annotations) == 0:
        return {
            "title": "No issues found",
            "summary": "All YAML files meet the configured style standard.",
        }

    annotations_plural = "" if len(annotations) == 1 else "s"
    files_plural = "" if len(files) == 1 else "s"
    do_plural = "es" if len(files) == 1 else ""
    return {
        "title": f"Found {len(annotations)} issue{annotations_plural} in {len(files)} file{files_plural}",
        "summary": f"The below file{files_plural} do{do_plural} not meet the configured style standard.",
        "annotations": annotations,
    }


def parse_mypy_annotations(source_path: str) -> Dict[str, Union[str, List[Dict[str, object]]]]:
    """
    Parses annotations for mypy

    :param source_path: the path to read for annotations
    :return: output object for the GitHub API
    """
    regex = r"\A(?P<path>.*)\:(?P<line>\d+)\: (?P<level>note|error)\: (?P<message>.*)\Z"
    files = set()
    annotations = []

    mypy_level_to_github_level = {"note": "notice", "error": "failure"}

    for source_file in listdir(source_path):
        with open(path.join(source_path, source_file), "r") as file:
            for line in file:
                annotation_parts = fullmatch(regex, line.strip())
                assert annotation_parts, f"Failed to parse line `{line.strip()}`"
                files.add(annotation_parts.group("path"))
                annotations.append(
                    {
                        "path": annotation_parts.group("path"),
                        "start_line": int(annotation_parts.group("line")),
                        "end_line": int(annotation_parts.group("line")),
                        "annotation_level": mypy_level_to_github_level[annotation_parts.group("level")],
                        "message": annotation_parts.group("message"),
                        "raw_details": dumps(annotation_parts.groupdict()),
                    }
                )

    if len(annotations) == 0:
        return {"title": "No issues found", "summary": "All Python files are type-safe."}

    annotations_plural = "" if len(annotations) == 1 else "s"
    files_plural = "" if len(files) == 1 else "s"
    is_plural = "is" if len(files) == 1 else "are"
    return {
        "title": f"Found {len(annotations)} issue{annotations_plural} in {len(files)} file{files_plural}",
        "summary": f"The below file{files_plural} {is_plural} not type-safe.",
        "annotations": annotations,
    }


def parse_flake8_annotations(source_path: str) -> Dict[str, Union[str, List[Dict[str, object]]]]:
    """
    Parses annotations for flake8

    :param source_path: the path to read for annotations
    :return: output object for the GitHub API
    """
    files = set()
    annotations = []

    for source_file in listdir(source_path):
        if stat(path.join(source_path, source_file)).st_size == 0:
            # Flake8 outputs zero bytes if there are no issues
            continue
        with open(path.join(source_path, source_file), "r") as file:
            flake8_json = load(file)

            for filename in flake8_json:
                for annotation in flake8_json[filename]:
                    files.add(filename)
                    annotations.append(
                        {
                            "path": filename,
                            "start_line": annotation["line_number"],
                            "end_line": annotation["line_number"],
                            "annotation_level": "failure",
                            "message": annotation["text"],
                            "raw_details": dumps(annotation),
                        }
                    )

    if len(annotations) == 0:
        return {
            "title": "No issues found",
            "summary": "All Python files meet the configured style standard.",
        }

    annotations_plural = "" if len(annotations) == 1 else "s"
    files_plural = "" if len(files) == 1 else "s"
    do_plural = "es" if len(files) == 1 else ""
    return {
        "title": f"Found {len(annotations)} issue{annotations_plural} in {len(files)} file{files_plural}",
        "summary": f"The below file{files_plural} do{do_plural} not meet the configured style standard.",
        "annotations": annotations,
    }


def parse_pylint_annotations(source_path: str) -> Dict[str, Union[str, List[Dict[str, object]]]]:
    """
    Parses annotations for pylint

    :param source_path: the path to read for annotations
    :return: output object for the GitHub API
    """
    files = set()
    annotations = []

    for source_file in listdir(source_path):
        with open(path.join(source_path, source_file), "r") as file:
            pylint_json = load(file)

            for annotation in pylint_json:
                files.add(annotation["path"])

                annotations.append(
                    {
                        "path": annotation["path"],
                        "start_line": annotation["line"],
                        "end_line": annotation["line"],
                        "annotation_level": "failure",
                        "message": annotation["message"],
                        "raw_details": dumps(annotation),
                    }
                )

    if len(files) == 0:
        return {
            "title": "No issues found",
            "summary": "All Python files meet the configured style standard.",
        }

    annotations_plural = "" if len(annotations) == 1 else "s"
    files_plural = "" if len(files) == 1 else "s"
    do_plural = "es" if len(files) == 1 else ""
    return {
        "title": f"Found {len(annotations)} issue{annotations_plural} in {len(files)} file{files_plural}",
        "summary": f"The below file{files_plural} do{do_plural} not meet the configured style standard.",
        "annotations": annotations,
    }


def parse_php_codesniffer_annotations(source_path: str) -> Dict[str, Union[str, List[Dict[str, object]]]]:
    """
    Parses annotations for PHP CodeSniffer

    :param source_path: the path to read for annotations
    :return: output object for the GitHub API
    """
    files = set()
    annotations = []

    phpcs_level_to_github_level = {"WARNING": "warning", "ERROR": "failure"}

    for source_file in listdir(source_path):
        with open(path.join(source_path, source_file), "r") as file:
            phpcs_json = load(file)

            for filename in phpcs_json["files"]:
                for annotation in phpcs_json["files"][filename]["messages"]:
                    cleaned_filename = filename.split("/")[-len(source_path.split("/")) :].join("/")  # noqa: E203
                    files.add(cleaned_filename)
                    annotations.append(
                        {
                            "path": cleaned_filename,
                            "start_line": annotation["line"],
                            "end_line": annotation["line"],
                            "annotation_level": phpcs_level_to_github_level[annotation["type"]],
                            "message": annotation["message"],
                            "raw_details": dumps(annotation),
                        }
                    )

    if len(files) == 0:
        return {
            "title": "No issues found",
            "summary": "All PHP files meet the configured style standard.",
        }

    annotations_plural = "" if len(annotations) == 1 else "s"
    files_plural = "" if len(files) == 1 else "s"
    do_plural = "es" if len(files) == 1 else ""
    return {
        "title": f"Found {len(annotations)} issue{annotations_plural} in {len(files)} file{files_plural}",
        "summary": f"The below file{files_plural} do{do_plural} not meet the configured style standard.",
        "annotations": annotations,
    }


def parse_phpstan_annotations(  # pylint: disable=R0914
    source_path: str, phpstan_neon_contents: List[str]
) -> Dict[str, Union[str, List[Dict[str, object]]]]:
    """
    Parses annotations for PHPStan

    :param source_path: the path to read for annotations
    :return: output object for the GitHub API
    """
    files = set()
    annotations = []

    error_regexes = (
        r"Ignored error pattern (?P<pattern>.+) was not matched in reported errors\.",
        r"No ending delimiter .+ found in pattern: (?P<pattern>.+)\.",
        r"Ignored error (?P<pattern>.+) has an unescaped anchor .+ in the middle\. This leads to unintended behavior\. Use .+ instead\.",  # noqa: E501  # pylint: disable=C0301
    )

    for source_file in listdir(source_path):
        with open(path.join(source_path, source_file), "r") as file:
            phpstan_json = load(file)

            for filename in phpstan_json["files"]:
                for annotation in phpstan_json["files"][filename]["messages"]:
                    cleaned_filename = filename.split("/")[-len(source_path.split("/")) :].join("/")  # noqa: E203
                    files.add(cleaned_filename)
                    annotations.append(
                        {
                            "path": cleaned_filename,
                            "start_line": annotation["line"],
                            "end_line": annotation["line"],
                            "annotation_level": "failure",
                            "message": annotation["message"],
                        }
                    )
                for error in phpstan_json["errors"]:
                    for regex in error_regexes:
                        error_match = fullmatch(regex, error)
                        if error_match:
                            break
                    assert error_match, f"Failed to parse line `{error}`"
                    pattern = error_match.group("pattern")

                    line_counter = 0
                    found = False
                    for line in phpstan_neon_contents:
                        line_counter += 1
                        if pattern in line:
                            found = True
                            break

                    assert found, "Expected to find pattern `{pattern}` in neon file"

                    files.add("phpstan.neon")
                    annotations.append(
                        {
                            "path": "phpstan.neon",
                            "start_line": line_counter,
                            "end_line": line_counter,
                            "annotation_level": "failure",
                            "message": error,
                        }
                    )

    if len(files) == 0:
        return {
            "title": "No issues found",
            "summary": "All PHP files meet the configured style standard.",
        }

    annotations_plural = "" if len(annotations) == 1 else "s"
    files_plural = "" if len(files) == 1 else "s"
    do_plural = "es" if len(files) == 1 else ""
    return {
        "title": f"Found {len(annotations)} issue{annotations_plural} in {len(files)} file{files_plural}",
        "summary": f"The below file{files_plural} do{do_plural} not meet the configured style standard.",
        "annotations": annotations,
    }


def parse_phan_annotations(source_path: str) -> Dict[str, Union[str, List[Dict[str, object]]]]:
    """
    Parses annotations for phan

    :param source_path: the path to read for annotations
    :return: output object for the GitHub API
    """
    files = set()
    annotations = []

    for source_file in listdir(source_path):
        with open(path.join(source_path, source_file), "r") as file:
            phan_json = load(file)

            for annotation in phan_json:
                files.add(annotation["location"]["path"])

                annotations.append(
                    {
                        "path": annotation["location"]["path"],
                        "start_line": annotation["location"]["lines"]["begin"],
                        "end_line": annotation["location"]["lines"]["begin"],
                        "annotation_level": "failure",
                        "message": annotation["description"],
                        "raw_details": dumps(annotation),
                    }
                )

    if len(files) == 0:
        return {
            "title": "No issues found",
            "summary": "All PHP files meet the configured style standard.",
        }

    annotations_plural = "" if len(annotations) == 1 else "s"
    files_plural = "" if len(files) == 1 else "s"
    do_plural = "es" if len(files) == 1 else ""
    return {
        "title": f"Found {len(annotations)} issue{annotations_plural} in {len(files)} file{files_plural}",
        "summary": f"The below file{files_plural} do{do_plural} not meet the configured style standard.",
        "annotations": annotations,
    }


def parse_psalm_annotations(source_path: str) -> Dict[str, Union[str, List[Dict[str, object]]]]:
    """
    Parses annotations for psalm

    :param source_path: the path to read for annotations
    :return: output object for the GitHub API
    """
    files = set()
    annotations = []

    psalm_severity_to_github_level = {
        "info": "notice",
        "error": "failure",
    }

    for source_file in listdir(source_path):
        with open(path.join(source_path, source_file), "r") as file:
            psalm_json = load(file)

            for annotation in psalm_json:
                files.add(annotation["file_name"])

                if annotation["line_from"] == annotation["line_to"]:
                    annotations.append(
                        {
                            "path": annotation["file_name"],
                            "start_line": annotation["line_from"],
                            "end_line": annotation["line_to"],
                            "start_column": annotation["column_from"],
                            "end_column": annotation["column_to"],
                            "annotation_level": psalm_severity_to_github_level[annotation["severity"]],
                            "message": annotation["message"],
                            "raw_details": dumps(annotation),
                        }
                    )
                else:
                    annotations.append(
                        {
                            "path": annotation["file_name"],
                            "start_line": annotation["line_from"],
                            "end_line": annotation["line_to"],
                            "annotation_level": psalm_severity_to_github_level[annotation["severity"]],
                            "message": annotation["message"],
                            "raw_details": dumps(annotation),
                        }
                    )

    if len(files) == 0:
        return {
            "title": "No issues found",
            "summary": "All PHP files meet the configured style standard.",
        }

    annotations_plural = "" if len(annotations) == 1 else "s"
    files_plural = "" if len(files) == 1 else "s"
    do_plural = "es" if len(files) == 1 else ""
    return {
        "title": f"Found {len(annotations)} issue{annotations_plural} in {len(files)} file{files_plural}",
        "summary": f"The below file{files_plural} do{do_plural} not meet the configured style standard.",
        "annotations": annotations,
    }


required_source_fields = ("repository", "token", "check_name", "resource_name")
optional_source_fields = ("annotations_format", "annotations_location", "pull_request", "debug")
conclusion_options = (
    "success",
    "failure",
    "neutral",
    "cancelled",
    "skipped",
    "timed_out",
    "action_required",
)

timestamp = timestamp_for_github()

assert len(argv) == 2

input_directory = argv[1]

assert path.exists(input_directory)
assert path.isdir(input_directory)

concourse_input = loads(stdin.read())

assert isinstance(concourse_input, dict)
assert "source" in concourse_input, "Missing required `source` fields"
assert isinstance(concourse_input["source"], dict), "`source` must be a dict, check pipeline configuration"

for source_field in required_source_fields:
    assert source_field in concourse_input["source"], f"Missing required field `{source_field}`in `source`"

for source_field in concourse_input["source"]:
    assert (
        source_field in required_source_fields or source_field in optional_source_fields
    ), f"Unexpected field `{source_field}` passed in `source`"

if "debug" in concourse_input["source"]:
    if not concourse_input["source"]["debug"] is True:
        print("Debug flag set to invalid value, check documentation")
        sys.exit(1)

    handler = logging.StreamHandler(stderr)
    handler.setLevel(logging.DEBUG)

    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    logger.addHandler(handler)

    logger.debug("Debug logging enabled")

repository = path.join(input_directory, concourse_input["source"]["repository"])

if not path.exists(repository) and "pull_request" in concourse_input["source"]:
    pull_request = path.join(input_directory, concourse_input["source"]["pull_request"])
    if path.exists(pull_request):
        repository = pull_request

assert path.exists(repository)
assert path.isdir(repository)

if len(listdir(input_directory)) > 3:
    print(
        "To improve performance, you may want to manually configure the inputs to this step.", file=stderr,
    )

git_rev_parse_output = run(["git", "-C", repository, "rev-parse", "HEAD"], text=True, capture_output=True, check=True)

git_remote_output = run(["git", "-C", repository, "remote", "--verbose"], text=True, capture_output=True, check=True)
if len(git_remote_output.stdout.strip()) == 0:
    with open(path.join(repository, ".git", "resource", "url"), "r") as url_file:
        remote = url_file.read().split("/")
else:
    remote = git_remote_output.stdout.strip().split("\n")[0].split("\t")[1].split("/")

host = remote[2]
api_base_url = "https://" + ("api.github.com" if host == "github.com" else host + "/api/v3")
owner = remote[3]
repo = remote[4].split(" ")[0]
head_sha = git_rev_parse_output.stdout.strip()
name = concourse_input["source"]["check_name"]

details_url = (
    getenv("ATC_EXTERNAL_URL")  # type: ignore
    + "/teams/"  # type: ignore
    + getenv("BUILD_TEAM_NAME")
    + "/pipelines/"
    + getenv("BUILD_PIPELINE_NAME")
    + "/jobs/"
    + getenv("BUILD_JOB_NAME")
    + "/builds/"
    + getenv("BUILD_NAME")
)

headers = {
    "Authorization": "Bearer " + concourse_input["source"]["token"],
    "User-Agent": "concourse-github-check-resource",
    "Accept": "application/vnd.github.antiope-preview+json",
}

state_file_path = path.join(input_directory, concourse_input["source"]["resource_name"], "state.json")

if path.exists(state_file_path):
    assert path.isfile(state_file_path)

    with open(state_file_path, "r") as state_file:
        state = load(state_file)

    assert isinstance(state, dict)
    assert isinstance(state["id"], str)

    check_id = state["id"]

    assert "params" in concourse_input, "`params` required to update an existing check"
    params = concourse_input["params"]
    assert isinstance(params, dict), "`params` must be a dict, check pipeline configuration"

    assert "conclusion" in params, "`conclusion` required in `params` to update an existing check"

    conclusion = params["conclusion"]

    assert (
        conclusion in conclusion_options
    ), "Invalid `conclusion` specified - refer to the GitHub API documentation for possible values"

    data = {
        "conclusion": conclusion,
        "completed_at": timestamp,
    }

    if "title" in params and "summary" in params:
        data["output"] = {
            "title": params["title"],
            "summary": params["summary"],
        }
    else:
        if conclusion == "cancelled":
            data["output"] = {
                "title": "Task cancelled by user",
                "summary": "Re-run the job within Concourse.",
            }
        if conclusion == "action_required":
            data["output"] = {
                "title": "Error running task",
                "summary": "Review the output within Concourse.",
            }

    if "annotations_format" in concourse_input["source"] and conclusion in ["success", "failure"]:
        annotations_format = concourse_input["source"]["annotations_format"]
        assert isinstance(annotations_format, str)
        if "annotations_location" in concourse_input["source"]:
            annotations_location = concourse_input["source"]["annotations_location"]
        else:
            annotations_location = annotations_format
        annotations_path = path.join(input_directory, annotations_location)
        assert path.exists(annotations_path), f"Make sure you added `{annotations_location}` to `inputs`"
        assert path.isdir(annotations_path)

        if len(listdir(annotations_path)) == 0:
            print("No input files found for annotations.", file=stderr)
        else:
            try:
                if annotations_format == "yamllint":
                    data["output"] = parse_yamllint_annotations(annotations_path)
                elif annotations_format == "flake8":
                    data["output"] = parse_flake8_annotations(annotations_path)
                elif annotations_format == "pylint":
                    data["output"] = parse_pylint_annotations(annotations_path)
                elif annotations_format == "mypy":
                    data["output"] = parse_mypy_annotations(annotations_path)
                elif annotations_format == "codesniffer":
                    data["output"] = parse_php_codesniffer_annotations(annotations_path)
                elif annotations_format == "phpstan":
                    with open(path.join(repository, "phpstan.neon"), "r") as phpstan_neon_file:
                        phpstan_neon = phpstan_neon_file.readlines()
                    data["output"] = parse_phpstan_annotations(annotations_path, phpstan_neon)
                elif annotations_format == "phan":
                    data["output"] = parse_phan_annotations(annotations_path)
                elif annotations_format == "psalm":
                    data["output"] = parse_psalm_annotations(annotations_path)
                else:
                    print(f"Invalid annotations format `{annotations_format}` passed.", file=stderr)
                    sys.exit(1)
            except Exception:  # pylint: disable=W0703
                print(format_exc(), file=stderr)
                data["output"] = {
                    "title": "Failed to parse annotations",
                    "summary": "Review the output within Concourse, or run `fly intercept --job="  # type: ignore
                    + getenv("BUILD_PIPELINE_NAME")
                    + "/"
                    + getenv("BUILD_JOB_NAME")
                    + " --build="
                    + getenv("BUILD_NAME")
                    + "` to examine the container.",
                }

    if "output" in data and "annotations" in data["output"] and len(data["output"]["annotations"]) > 0:
        original_annotations = data["output"]["annotations"]
        CHECKS_PER_CALL = 50  # GitHub API only accepts 50 annotations per call
        for chunked_annotations in [
            original_annotations[i * CHECKS_PER_CALL : (i + 1) * CHECKS_PER_CALL]  # noqa: E203
            for i in range((len(original_annotations) + CHECKS_PER_CALL - 1) // CHECKS_PER_CALL)
        ]:
            data["output"]["annotations"] = chunked_annotations
            response = patch(f"{api_base_url}/repos/{owner}/{repo}/check-runs/{check_id}", json=data, headers=headers,)
            assert (
                response.status_code == 200
            ), f"Got unexpected response code {response.status_code} from GitHub: {response.json()}"
    else:
        response = patch(f"{api_base_url}/repos/{owner}/{repo}/check-runs/{check_id}", json=data, headers=headers)
        assert (
            response.status_code == 200
        ), f"Got unexpected response code {response.status_code} from GitHub: {response.json()}"

    url = response.json()["url"]
    html_url = response.json()["html_url"]

    print(
        dumps(
            {
                "version": {"id": check_id},
                "metadata": [{"name": "url", "value": url}, {"name": "html_url", "value": html_url},],  # noqa: E231
            }
        )
    )
else:
    data = {
        "name": name,
        "head_sha": head_sha,
        "details_url": details_url,
        "status": "in_progress",
        "started_at": timestamp_for_github(),
    }

    response = post(f"{api_base_url}/repos/{owner}/{repo}/check-runs", json=data, headers=headers)
    assert (
        response.status_code == 201
    ), f"Got unexpected response code {response.status_code} from GitHub: {response.json()}"

    json = response.json()

    check_id = json["id"]
    url = json["url"]
    html_url = json["html_url"]

    print(
        dumps(
            {
                "version": {"id": str(check_id)},
                "metadata": [{"name": "url", "value": url}, {"name": "html_url", "value": html_url},],  # noqa: E231
            }
        )
    )
